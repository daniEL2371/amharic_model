{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>> This is L3Morpho, version 3.0 <<<<<\n",
      ">>>>>  and HornMorpho, version 2.5  <<<<<\n",
      "WARNING:tensorflow:From c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import random\n",
    "from tempfile import gettempdir\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "import l3\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 4089439\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = \"data/news.txt\"\n",
    "\n",
    "vocabulary = tf.compat.as_str(open(filename, encoding='utf8').read()).split()\n",
    "print('Data size', len(vocabulary))\n",
    "\n",
    "# Step 2: Build the dictionary and replace rare words with UNK token.\n",
    "vocabulary_size = 50000\n",
    "\n",
    "\n",
    "def build_dataset(words, n_words):\n",
    "    \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 0)\n",
    "        if index == 0:  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words (+UNK) [['UNK', 401045], ('*', 239982), ('ነው', 56425), ('#', 45253), ('ላይ', 37050)]\n",
      "Sample data [2752, 3645, 997, 0, 1633, 44513, 1968, 417, 953, 113] ['ጋዜጠኛ', 'ተመስገን', 'ደሳለኝ', 'UNK', 'በአቶ', 'አምሐ', 'መኮንን', 'አማካይነት', 'በፌዴራል', 'ጠቅላይ']\n"
     ]
    }
   ],
   "source": [
    "data, count, dictionary, reverse_dictionary = build_dataset(\n",
    "    vocabulary, vocabulary_size)\n",
    "del vocabulary  # Hint to reduce memory.\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data', data[:10], [reverse_dictionary[i] for i in data[:10]])\n",
    "\n",
    "data_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_similarity_on(word1, word2, startIndex):\n",
    "    sim = 0\n",
    "    for i in range(len(word2)):\n",
    "        if word1[i + startIndex] == word2[i]:\n",
    "            sim += 1\n",
    "    return sim\n",
    "\n",
    "\n",
    "def get_similarity(word1, word2):\n",
    "    max_sim = 0\n",
    "    if len(word1) == 0 or len(word2) == 0:\n",
    "        return 0\n",
    "    if len(word1) < len(word2):\n",
    "        word2, word1 = word1, word2\n",
    "    r = len(word1) - len(word2)\n",
    "    for j in range(r + 1):\n",
    "        sim = get_similarity_on(word1, word2, j)\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "    return max_sim / len(word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n",
      "0.04\n",
      "0.06\n",
      "0.08\n",
      "0.1\n",
      "0.12\n",
      "0.14\n",
      "0.16\n",
      "0.18\n",
      "0.2\n",
      "0.22\n",
      "0.24\n",
      "0.26\n",
      "0.28\n",
      "0.3\n",
      "0.32\n",
      "0.34\n",
      "0.36\n",
      "0.38\n",
      "0.4\n",
      "0.42\n",
      "0.44\n",
      "0.46\n",
      "0.48\n",
      "0.5\n",
      "0.52\n",
      "0.54\n",
      "0.56\n",
      "0.58\n",
      "0.6\n",
      "0.62\n",
      "0.64\n",
      "0.66\n",
      "0.68\n",
      "0.7\n",
      "0.72\n",
      "0.74\n",
      "0.76\n",
      "0.78\n",
      "0.8\n",
      "0.82\n",
      "0.84\n",
      "0.86\n",
      "0.88\n",
      "0.9\n",
      "0.92\n",
      "0.94\n",
      "0.96\n",
      "0.98\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "sim_dict  = {}\n",
    "j = 0\n",
    "file = open('data/sims.txt', encoding='utf8', mode='a')\n",
    "for word1 in dictionary.keys():\n",
    "    sims = []\n",
    "    j += 1\n",
    "    for word2 in  dictionary.keys():\n",
    "        if word1 != word2:\n",
    "            sim = get_similarity(word1, word2)\n",
    "            if sim > 0.6:\n",
    "                sims.append(word2)\n",
    "        if len(sims) >= 10:\n",
    "            break\n",
    "            \n",
    "    if len(sims) == 0:\n",
    "        sims.append(word1)\n",
    "    line = word1 + ' ' + ' '.join(sims) + '\\n'\n",
    "    file.write(line)\n",
    "    if j % 1000 == 0:\n",
    "        print(\"{0:.2}\".format(j/len(dictionary)))\n",
    "\n",
    "file.close()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
