{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_gen.ipynb\n",
    "%run models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGen(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = int(len(dg.vocab)/100)\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = dg.gen(batch_size=batch_size, n_batches=n_batches, windows_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model, aux_model = conv_model(len(dg.vocab), 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 15.8700 - acc: 9.1912e-04word  1178\n",
      "147/147 [==============================] - 12s 84ms/step - loss: 15.8886 - acc: 8.5034e-04\n",
      "Epoch 2/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 3/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 4/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 5/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 6/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 7/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 70ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 8/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 9/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 9s 59ms/step - loss: 16.0770 - acc: 0.0026 0s - loss: 16.0764 - acc: 0.\n",
      "Epoch 10/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 9s 60ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 11/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 11s 75ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 12/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 11s 72ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 13/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 70ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 14/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 67ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 15/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 16/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028 ETA: 1s - loss:word  1178\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 17/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 67ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 18/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 68ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 19/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 68ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 20/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 69ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 21/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 70ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 22/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 68ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 23/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 69ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 24/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 67ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 25/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 26/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 67ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 27/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 67ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 28/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 29/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 30/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 31/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 67ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 32/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 69ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 33/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 70ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 34/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 11s 73ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 35/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 67ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 36/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 68ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 37/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 67ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 38/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 67ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 39/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028 ETA: 0s - loss: 16.0730 - acc: 0.word  1178\n",
      "147/147 [==============================] - 10s 67ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 40/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 41/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028 ETA: 1s - loss: 16.0712word  1178\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 42/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 67ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 43/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 10s 66ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 44/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 67ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 45/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 68ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 46/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 9s 65ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 47/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 48/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 49/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 50/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 51/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 52/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 53/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 54/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 55/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 56/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028 ETA: 1s - lword  1178\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 57/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 58/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 59/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 16.0770 - acc: 0.0026\n",
      "Epoch 60/60\n",
      "136/147 [==========================>...] - ETA: 0s - loss: 16.0737 - acc: 0.0028word  1178\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 16.0770 - acc: 0.0026\n"
     ]
    }
   ],
   "source": [
    "history = main_model.fit_generator(gen, steps_per_epoch=n_batches, epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeds = {}\n",
    "for i in range(30):\n",
    "    x, y = next(gen)\n",
    "    embedding = aux_model.predict(x)\n",
    "    words = dg.one_hot_decode(y)\n",
    "    for j in range(len(y)):\n",
    "        word_embeds[words[j]] = embedding[j]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(v, u):\n",
    "    return np.sqrt(np.sum((v-u) ** 2))\n",
    "def cosine(u, v):\n",
    "    return u.dot(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(word, embedding):\n",
    "    min_distance = 1000\n",
    "    close_words = []\n",
    "    word_vec = embedding[word]\n",
    "    for key in embedding.keys():\n",
    "        vector = embedding[key]\n",
    "        if euclidean_dist(vector, word_vec) < min_distance and not np.array_equal(vector, word_vec):\n",
    "            min_distance = euclidean_dist(vector, word_vec)\n",
    "            close_words.append(key)\n",
    "    close_words.reverse()\n",
    "    return close_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ''\n",
    "file = open('sim/sigmoid_wr_0pa44d_100_e50_b100_nb40.txt', 'w', encoding='utf-8')\n",
    "for key in word_embeds:\n",
    "    s += key + ' : '\n",
    "    s += ' '.join(find_closest(key, word_embeds)[:5])\n",
    "    s += '\\n'\n",
    "    file.write(s)\n",
    "    s = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u2_word = 'በእርሱ'\n",
    "# v1 = word_embeds['በእንግሊዝ']\n",
    "# v2 = word_embeds['ከእንግሊዝ']\n",
    "# u1 = word_embeds[u2_word]\n",
    "# v = v1 - v2 + u1\n",
    "# v_norm = np.linalg.norm(v)\n",
    "# m_u = -99999\n",
    "# m_word = None\n",
    "# for key in word_embeds.keys():\n",
    "#     u2 = word_embeds[key]\n",
    "#     d = v.dot(u2)/v_norm\n",
    "#     if d > m_u and key != u2_word:\n",
    "#         m_u = d\n",
    "#         m_word = key\n",
    "#         print(key)\n",
    "    \n",
    "    \n",
    "# print(m_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "np.random.seed(200)\n",
    "\n",
    "cho = [np.random.randint(3000) for k in range(100)] \n",
    "visualizeWords = [dg.words[i] for i in cho]\n",
    "\n",
    "visualizeVecs = []\n",
    "visWords = []\n",
    "for j in range(len(visualizeWords)):\n",
    "    key = visualizeWords[j]\n",
    "    if key in word_embeds:\n",
    "        visualizeVecs.append(word_embeds[key])\n",
    "        visWords.append(key)\n",
    "        \n",
    "visualizeVecs = visualizeVecs[:50]\n",
    "visualizeWords = visWords[:50]\n",
    "temp = (visualizeVecs - np.mean(visualizeVecs, axis=0))\n",
    "covariance = 1.0 / len(visualizeVecs) * temp.T.dot(temp)\n",
    "U,S,V = np.linalg.svd(covariance)\n",
    "coord = temp.dot(U[:,0:2])\n",
    "print(coord.shape)\n",
    "for i in range(len(visualizeWords)):\n",
    "#     print(visualizeWords[i])\n",
    "    plt.text(coord[i,0], coord[i,1], visualizeWords[i],\n",
    "        bbox=dict(facecolor='green', alpha=0.1))\n",
    "\n",
    "    \n",
    "plt.rc('font', family='Abyssinica SIL')\n",
    "plt.xlim((np.min(coord[:,0]), np.max(coord[:,0])))\n",
    "plt.ylim((np.min(coord[:,1]), np.max(coord[:,1])))\n",
    "plt.show()\n",
    "# plt.savefig('images/q3_word_vectors.png')\n",
    "cho = None\n",
    "visWords = None\n",
    "visualizeVecs = None\n",
    "visualizeWords = None\n",
    "plt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
