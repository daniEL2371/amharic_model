{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import random\n",
    "from tempfile import gettempdir\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "import l3\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 4089439\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = \"data/news.txt\"\n",
    "\n",
    "vocabulary = tf.compat.as_str(open(filename, encoding='utf8').read()).split()\n",
    "print('Data size', len(vocabulary))\n",
    "\n",
    "# Step 2: Build the dictionary and replace rare words with UNK token.\n",
    "vocabulary_size = 50000\n",
    "\n",
    "\n",
    "def build_dataset(words, n_words):\n",
    "    \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 0)\n",
    "        if index == 0:  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words (+UNK) [['UNK', 401045], ('*', 239982), ('ነው', 56425), ('#', 45253), ('ላይ', 37050)]\n",
      "Sample data [2752, 3645, 997, 0, 1633, 44513, 1968, 417, 953, 113] ['ጋዜጠኛ', 'ተመስገን', 'ደሳለኝ', 'UNK', 'በአቶ', 'አምሐ', 'መኮንን', 'አማካይነት', 'በፌዴራል', 'ጠቅላይ']\n"
     ]
    }
   ],
   "source": [
    "data, count, dictionary, reverse_dictionary = build_dataset(\n",
    "    vocabulary, vocabulary_size)\n",
    "del vocabulary  # Hint to reduce memory.\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data', data[:10], [reverse_dictionary[i] for i in data[:10]])\n",
    "\n",
    "data_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_similarity_on(word1, word2, startIndex):\n",
    "    sim = 0\n",
    "    for i in range(len(word2)):\n",
    "        if word1[i + startIndex] == word2[i]:\n",
    "            sim += 1\n",
    "    return sim\n",
    "\n",
    "\n",
    "def get_similarity(word1, word2):\n",
    "    max_sim = 0\n",
    "    if len(word1) == 0 or len(word2) == 0:\n",
    "        return 0\n",
    "    if len(word1) < len(word2):\n",
    "        word2, word1 = word1, word2\n",
    "    r = len(word1) - len(word2)\n",
    "    for j in range(r + 1):\n",
    "        sim = get_similarity_on(word1, word2, j)\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "    return max_sim / len(word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2e-05\n",
      "4e-05\n",
      "6e-05\n",
      "8e-05\n",
      "0.0001\n",
      "0.00012\n",
      "0.00014\n",
      "0.00016\n",
      "0.00018\n",
      "0.0002\n",
      "0.00022\n",
      "0.00024\n",
      "0.00026\n",
      "0.00028\n",
      "0.0003\n",
      "0.00032\n",
      "0.00034\n",
      "0.00036\n",
      "0.00038\n",
      "0.0004\n",
      "0.00042\n",
      "0.00044\n",
      "0.00046\n",
      "0.00048\n",
      "0.0005\n",
      "0.00052\n",
      "0.00054\n",
      "0.00056\n",
      "0.00058\n",
      "0.0006\n",
      "0.00062\n",
      "0.00064\n",
      "0.00066\n",
      "0.00068\n",
      "0.0007\n",
      "0.00072\n",
      "0.00074\n",
      "0.00076\n",
      "0.00078\n",
      "0.0008\n",
      "0.00082\n",
      "0.00084\n",
      "0.00086\n",
      "0.00088\n",
      "0.0009\n",
      "0.00092\n",
      "0.00094\n",
      "0.00096\n",
      "0.00098\n",
      "0.001\n",
      "0.001\n",
      "0.001\n",
      "0.0011\n",
      "0.0011\n",
      "0.0011\n",
      "0.0011\n",
      "0.0011\n",
      "0.0012\n",
      "0.0012\n",
      "0.0012\n",
      "0.0012\n",
      "0.0012\n",
      "0.0013\n",
      "0.0013\n",
      "0.0013\n",
      "0.0013\n",
      "0.0013\n",
      "0.0014\n",
      "0.0014\n",
      "0.0014\n",
      "0.0014\n",
      "0.0014\n",
      "0.0015\n",
      "0.0015\n",
      "0.0015\n",
      "0.0015\n",
      "0.0015\n",
      "0.0016\n",
      "0.0016\n",
      "0.0016\n",
      "0.0016\n",
      "0.0016\n",
      "0.0017\n"
     ]
    }
   ],
   "source": [
    "sim_dict  = {}\n",
    "j = 0\n",
    "file = open('data/sims.txt', encoding='utf8', mode='a')\n",
    "for word1 in dictionary.keys():\n",
    "    sims = []\n",
    "    j += 1\n",
    "    for word2 in  dictionary.keys():\n",
    "        if word1 != word2:\n",
    "            sim = get_similarity(word1, word2)\n",
    "            if sim > 0.6:\n",
    "                sims.append(word2)\n",
    "        if len(sims) >= 10:\n",
    "            break\n",
    "            \n",
    "    if len(sims) == 0:\n",
    "        sims.append(word1)\n",
    "    line = word1 + ' ' + ' '.join(sims) + '\\n'\n",
    "    file.write(line)\n",
    "    if j % 1000 == 0:\n",
    "        print(\"{0:.2}\".format(j/len(dictionary)))\n",
    "\n",
    "file.close()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
